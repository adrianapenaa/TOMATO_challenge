{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a40abca3-9408-4381-95c1-a57450615f38",
   "metadata": {},
   "source": [
    "# Part 2: Model Build and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a502d3-91c0-44f0-91a6-d681c32f862d",
   "metadata": {},
   "source": [
    "This notebook is structured to help guide you through the second half of this challenge. If additional cells are needed to build and train your classifier, please feel free to use additional cells. Otherwise please refrain from adding cells at any point in the notebook during this challenge. Please also do not delete or modify the provided headers to the cells. You are welcome to additional comments, though, if needed! Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d230d5-5c42-4408-8151-709baf34a860",
   "metadata": {},
   "source": [
    "### Import your libraries in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0a7d24-33fd-49c6-af0a-76929a7d978d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# imports for data pre-processing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34e6b21-5a72-47da-bd04-d61a29b81b8d",
   "metadata": {},
   "source": [
    "### Import in your csv from the previous notebook in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bbba31d-503b-4976-8537-980a6bf129e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data:\n",
    "df = pd.read_csv('cleaned_train_data.csv')\n",
    "# test data:\n",
    "# df = pd.read_csv('cleaned_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca17ebc4-8bfa-4c09-96f8-1c853196b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Phrase = df.Phrase.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8953a2-4891-4b6f-a697-9ad14175060b",
   "metadata": {},
   "source": [
    "### Build and Train your Classifier in this and the following cell(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e419cd07-7d89-4598-ba57-456b1a4f653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-preprocessing\n",
    "\n",
    "X = df.Phrase\n",
    "y = df.Sentiment\n",
    "tokenize = Tokenizer()\n",
    "tokenize.fit_on_texts(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "252810ba-eb35-4a89-97c6-b9aa5daf7f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "\n",
    "X = tokenize.texts_to_sequences(X)\n",
    "max_length = max([len(s.split()) for s in df['Phrase']])\n",
    "X = pad_sequences(X, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e4284e-170c-4103-a4b0-56f1d2e118a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "unknown = len(tokenize.word_index)+1\n",
    "model = Sequential()\n",
    "model.add(Embedding(unknown, EMBEDDING_DIM, input_length=max_length))\n",
    "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2 ))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8930065c-940f-416a-8749-725e04f00010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 29, 100)           1207600   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,325,493\n",
      "Trainable params: 1,325,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242985bc-a6f9-4d27-b60e-00e02dd052fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "732/732 [==============================] - 117s 156ms/step - loss: 0.9944 - accuracy: 0.6041\n",
      "Epoch 2/7\n",
      "732/732 [==============================] - 110s 150ms/step - loss: 0.7717 - accuracy: 0.6868\n",
      "Epoch 3/7\n",
      "732/732 [==============================] - 108s 148ms/step - loss: 0.7052 - accuracy: 0.7090\n",
      "Epoch 4/7\n",
      "732/732 [==============================] - 109s 149ms/step - loss: 0.6596 - accuracy: 0.7242\n",
      "Epoch 5/7\n",
      "732/732 [==============================] - 114s 156ms/step - loss: 0.6202 - accuracy: 0.7379\n",
      "Epoch 6/7\n",
      "732/732 [==============================] - 114s 156ms/step - loss: 0.5867 - accuracy: 0.7483\n",
      "Epoch 7/7\n",
      "673/732 [==========================>...] - ETA: 9s - loss: 0.5577 - accuracy: 0.7582"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=7, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b9ca3-2043-44dd-9eef-ea4c7992bea6",
   "metadata": {},
   "source": [
    "### Create your Predictions in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3e0b89-89cb-4301-b870-65b63554b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('cleaned_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855c03a-7236-4fbd-82d1-706fb88f3c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.Phrase\n",
    "df_test.Phrase = df_test.Phrase.astype(str)\n",
    "X_test = tokenize.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b13774-6ae9-4151-afd9-07cff3e102b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27298f-921f-43c4-9b7b-c0cb0c654252",
   "metadata": {},
   "source": [
    "### Perform the final evaluation of the Performance of your model in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4e01e-41ab-407b-bd0d-8172168a1dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
